{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, glob, string, re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import svm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Activation, Embedding, Dropout, TimeDistributed\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras import metrics\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "from numpy.random import seed\n",
    "seed(9)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"student\", \"faculty\", \"staff\", \"department\", \"course\", \"project\", \"other\"]\n",
    "class_index = dict((c, i) for i, c in enumerate(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'student': 0, 'faculty': 1, 'staff': 2, 'department': 3, 'course': 4, 'project': 5, 'other': 6}\n"
     ]
    }
   ],
   "source": [
    "print(class_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create list of all files, along with their classes\n",
    "all_files varia\n",
    "all_files : {\"student\": [[\"file_path\"],[\"file_path\"]], \"course\": [[\"file_path2\", \"file_path3\"]]}\n",
    "\"\"\"\n",
    "all_files = {}\n",
    "path = \"data/raw/webkb/\"\n",
    "all_folders = os.listdir(path)\n",
    "for clz in all_folders:\n",
    "    if clz.startswith('.'):\n",
    "        continue\n",
    "    if clz not in all_files:\n",
    "        all_files[clz] = []\n",
    "    path_with_clz = path + clz + '/'\n",
    "    all_univs = os.listdir(path_with_clz)\n",
    "    for univ in all_univs:\n",
    "        if univ.startswith('.'):\n",
    "            continue\n",
    "        path_with_univs = path_with_clz + univ + '/'\n",
    "        all_files[clz].append(glob.glob(os.path.join(path_with_univs, '*')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(all_files[\"department\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['faculty', 'course', 'other', 'student', 'department', 'project', 'staff'])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "to take only sample of all files\n",
    "\"\"\"\n",
    "short_all_files = {}\n",
    "max_count = 2\n",
    "print(all_files.keys())\n",
    "for k, v in all_files.items():\n",
    "    if k not in short_all_files:\n",
    "            short_all_files[k] = []\n",
    "    short_all_files[k] = v[:max_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(short_all_files['student'][:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_local = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not read_local:\n",
    "    raw = []\n",
    "    for k, v in all_files.items():\n",
    "        for fnames in v:\n",
    "            for fs in fnames:\n",
    "                with open(fs, 'rb') as f:\n",
    "                    raw_data = f.read()\n",
    "                    raw.append([raw_data, class_index[k]])\n",
    "\n",
    "    raw_df = pd.DataFrame(raw, columns=[\"text\", \"Class\"])\n",
    "else:\n",
    "    raw_df = pd.read_csv('raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8282, 2)\n"
     ]
    }
   ],
   "source": [
    "print(raw_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_df.to_csv('raw.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_features = 100\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=no_features)\n",
    "tfidf_vectorizer2 = TfidfVectorizer(max_df=0.95, min_df=2, max_features=no_features)\n",
    "tfidf_vectorizer3 = TfidfVectorizer(ngram_range=(1, 2), max_df=0.95, min_df=2, max_features=no_features)\n",
    "tf_vectorizer = CountVectorizer(max_features=no_features)\n",
    "stopset = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(txt):\n",
    "    cleantext = BeautifulSoup(txt, \"lxml\").text\n",
    "    tokens = []\n",
    "    for token in wordpunct_tokenize(cleantext):\n",
    "        if token.isdigit():\n",
    "            continue\n",
    "        if all(char in string.punctuation for char in token):\n",
    "            continue\n",
    "        \n",
    "        token = token.lower()\n",
    "        token = token.strip()  # Strip whitespace and other punctuations\n",
    "        token = token.strip('_')  # remove _ if any\n",
    "        token = token.strip('*')\n",
    "        if token in stopset:\n",
    "            continue\n",
    "        tokens.append(token)\n",
    "        lemmatizer.lemmatize(token)\n",
    "#     x = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(txt, vectorizer):\n",
    "    X = vectorizer.fit_transform(txt)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_vectorization(txt):\n",
    "    X_tf = tf_vectorizer.fit_transform(txt)\n",
    "    return X_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = raw_df.sample(frac=0.1, replace=True)\n",
    "df = raw_df\n",
    "df['processed_text'] = df['text'].apply(process)\n",
    "df['processed_text_cnct'] = df['processed_text'].apply(lambda tokens: ' '.join(str(v) for v in tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n",
      "0    1641\n",
      "1    1124\n",
      "2     137\n",
      "3     182\n",
      "4     930\n",
      "5     504\n",
      "6    3764\n",
      "dtype: int64\n",
      "(8282, 4)\n"
     ]
    }
   ],
   "source": [
    "class_counts = df.groupby(['Class']).size()\n",
    "print(class_counts)\n",
    "print(df.shape)\n",
    "# class_counts_raw = raw_df.groupby(['Class']).size()\n",
    "# print(class_counts_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 20000\n",
    "tokenizer = Tokenizer(num_words=vocab_size)\n",
    "tokenizer.fit_on_texts(df['processed_text_cnct'])\n",
    "sequences = tokenizer.texts_to_sequences(df['processed_text_cnct'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg = sum( map(len, sequences) ) / len(sequences)\n",
    "std = np.sqrt(sum( map(lambda x: (len(x) - avg)**2, sequences)) / len(sequences))\n",
    "\n",
    "print(avg,std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average text is 225 in length, let's restrict sequence length to 150 words.\n",
    "max_length = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pad_sequences(sequences, maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = to_categorical(np.asarray(df['Class']))\n",
    "print('Shape of data:', data.shape)\n",
    "print('Shape of labels:', labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data\n",
    "y = labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 100, input_length=max_length))\n",
    "model.add(LSTM(32, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(32, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(7))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[metrics.mae, metrics.categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=20, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tf = vectorize(df['processed_text_cnct'], tfidf_vectorizer2)\n",
    "\n",
    "no_topics = 15\n",
    "num_iter = 5\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=no_topics, max_iter=num_iter, learning_method='online', learning_offset=50.,random_state=9, evaluate_every=100).fit(X_tf)\n",
    "\n",
    "lda_x = lda.transform(X_tf)\n",
    "print(lda_x.shape)\n",
    "\n",
    "tf_feature_names = tfidf_vectorizer2.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_top_words = 10\n",
    "topic_indices = []\n",
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (topic_idx))\n",
    "        top_features = [feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]\n",
    "        print(\" \".join(top_features))\n",
    "\n",
    "display_topics(lda, tf_feature_names, no_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidf = vectorize(df['processed_text_cnct'], tfidf_vectorizer3)\n",
    "X = X_tfidf\n",
    "# X = X.todense()\n",
    "y = df['Class']\n",
    "# X = lda_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8282, 100)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler(with_mean = False).fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#0 in train set: 1231\n",
      "#0 in test set: 410\n",
      "#1 in train set: 843\n",
      "#1 in test set: 281\n",
      "#2 in train set: 103\n",
      "#2 in test set: 34\n",
      "#3 in train set: 136\n",
      "#3 in test set: 46\n",
      "#4 in train set: 697\n",
      "#4 in test set: 233\n",
      "#5 in train set: 378\n",
      "#5 in test set: 126\n",
      "#6 in train set: 2823\n",
      "#6 in test set: 941\n"
     ]
    }
   ],
   "source": [
    "for i in range(7):\n",
    "    print(\"#{} in train set: {}\".format(i, len(y_train[y_train == i])))\n",
    "    print(\"#{} in test set: {}\".format(i, len(y_test[y_test == i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = ['precision_macro', 'recall_macro']\n",
    "estimators = []\n",
    "clf1 = MultinomialNB()\n",
    "estimators.append(clf1)\n",
    "clf2 = svm.SVC(C=100, kernel='linear')\n",
    "estimators.append(clf2)\n",
    "eclf = VotingClassifier(estimators=[('nb', clf1), ('svm', clf2)], voting='hard')\n",
    "for clf, label in zip([clf1, clf2, eclf], ['Naive Bayes', 'SVM', 'Ensemble']):\n",
    "    scores = cross_val_score(clf, X, y, cv=5, scoring='f1_micro')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))\n",
    "# clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clf = svm.SVC(C=100, kernel='linear')\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MultinomialNB' object has no attribute 'n_support_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-2b0c7f77f9ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_support_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'MultinomialNB' object has no attribute 'n_support_'"
     ]
    }
   ],
   "source": [
    "print(clf.n_support_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[283  47  18  15   5  16  26]\n",
      " [ 52 163   5  17   5  33   6]\n",
      " [ 15   5   5   1   1   4   3]\n",
      " [  2   2   2  38   0   0   2]\n",
      " [ 19   8   1   4 163  11  27]\n",
      " [  8  11   0   5   5  86  11]\n",
      " [ 89  45   4  44  78 108 573]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_true, y_pred)\n",
    "# cm = confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "print(cm)\n",
    "cm_np = np.asarray(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[283 163   5  38 163  86 573]\n"
     ]
    }
   ],
   "source": [
    "TP = np.diag(cm_np)\n",
    "print(TP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[185 118  30  86  94 172  75]\n"
     ]
    }
   ],
   "source": [
    "FP = np.sum(cm, axis=0) - TP\n",
    "print(FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[127 118  29   8  70  40 368]\n"
     ]
    }
   ],
   "source": [
    "FN = np.sum(cm, axis=1) - TP\n",
    "print(FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1476, 1672, 2007, 1939, 1744, 1773, 1055]\n"
     ]
    }
   ],
   "source": [
    "num_classes = 7\n",
    "TN = []\n",
    "for i in range(num_classes):\n",
    "    temp = np.delete(cm, i, 0)    # delete ith row\n",
    "    temp = np.delete(temp, i, 1)  # delete ith column\n",
    "    TN.append(sum(sum(temp)))\n",
    "print(TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy [0.84934814 0.88604539 0.97151135 0.9546113  0.9208112  0.89763399\n",
      " 0.78609367]\n",
      "precision [0.60470085 0.58007117 0.14285714 0.30645161 0.63424125 0.33333333\n",
      " 0.88425926]\n",
      "recall [0.6902439  0.58007117 0.14705882 0.82608696 0.69957082 0.68253968\n",
      " 0.60892667]\n",
      "f1 [0.64464692 0.58007117 0.14492754 0.44705882 0.66530612 0.44791667\n",
      " 0.72120831]\n"
     ]
    }
   ],
   "source": [
    "prec = TP/(TP+FP)\n",
    "rec = TP/(TP+FN)\n",
    "acc = (TP+TN)/(TP+FP+TN+FN)\n",
    "f1 = 2*prec*rec/(prec+rec)\n",
    "\n",
    "print(\"accuracy\", acc)\n",
    "print(\"precision\", prec)\n",
    "print(\"recall\", rec)\n",
    "print(\"f1\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_eval_metrics(x, y, y2, y3, y4, img_name):\n",
    "    fig, ax = plt.subplots()\n",
    "    y_label = \"value\"\n",
    "    x_label = \"classes\"\n",
    "    plt.plot(x, y, color='b', marker='o', label=\"Accuracy\")\n",
    "    plt.plot(x, y2, color='g', marker='+', label=\"Precision\")\n",
    "    plt.plot(x, y3, color='y', marker='x', label=\"Recall\")\n",
    "    plt.plot(x, y4, color='r', marker='s', label=\"F1-measure\")\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.legend()\n",
    "#     plt.scatter(x, y, label=\"Accuracy\")\n",
    "#     plt.scatter(x, y2, label=\"Precision\")\n",
    "#     plt.scatter(x, y3, label=\"Recall\")\n",
    "#     plt.scatter(x, y4, label=\"F1-measure\")\n",
    "    plt.show()\n",
    "    fig.savefig(img_name)\n",
    "#     plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_eval_metrics(classes, acc, prec, rec, f1, \"tfidf-mNB.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
